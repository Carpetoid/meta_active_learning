{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "from __future__ import print_function, division\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMBALANCECIFAR10(torchvision.datasets.CIFAR10):\n",
    "    cls_num = 10\n",
    "\n",
    "    def __init__(self, root, imb_type='exp', imb_factor=0.01, rand_number=0, train=True,\n",
    "                 transform=None, target_transform=None,\n",
    "                 download=True):\n",
    "        super(IMBALANCECIFAR10, self).__init__(root, train, transform, target_transform, download)\n",
    "        np.random.seed(rand_number)\n",
    "        img_num_list = self.get_img_num_per_cls(self.cls_num, imb_type, imb_factor)\n",
    "        self.gen_imbalanced_data(img_num_list)\n",
    "\n",
    "    def get_img_num_per_cls(self, cls_num, imb_type, imb_factor):\n",
    "        img_max = len(self.data) / cls_num\n",
    "        img_num_per_cls = []\n",
    "        if imb_type == 'exp':\n",
    "            for cls_idx in range(cls_num):\n",
    "                num = img_max * (imb_factor**(cls_idx / (cls_num - 1.0)))\n",
    "                img_num_per_cls.append(int(num))\n",
    "        elif imb_type == 'step':\n",
    "            for cls_idx in range(cls_num // 2):\n",
    "                img_num_per_cls.append(int(img_max))\n",
    "            for cls_idx in range(cls_num // 2):\n",
    "                img_num_per_cls.append(int(img_max * imb_factor))\n",
    "        else:\n",
    "            img_num_per_cls.extend([int(img_max)] * cls_num)\n",
    "        return img_num_per_cls\n",
    "\n",
    "    def gen_imbalanced_data(self, img_num_per_cls):\n",
    "        new_data = []\n",
    "        new_targets = []\n",
    "        targets_np = np.array(self.targets, dtype=np.int64)\n",
    "        classes = np.unique(targets_np)\n",
    "        # np.random.shuffle(classes)\n",
    "        self.num_per_cls_dict = dict()\n",
    "        for the_class, the_img_num in zip(classes, img_num_per_cls):\n",
    "            self.num_per_cls_dict[the_class] = the_img_num\n",
    "            idx = np.where(targets_np == the_class)[0]\n",
    "            np.random.shuffle(idx)\n",
    "            selec_idx = idx[:the_img_num]\n",
    "            new_data.append(self.data[selec_idx, ...])\n",
    "            new_targets.extend([the_class, ] * the_img_num)\n",
    "        new_data = np.vstack(new_data)\n",
    "        self.data = new_data\n",
    "        self.targets = new_targets\n",
    "        \n",
    "    def get_cls_num_list(self):\n",
    "        cls_num_list = []\n",
    "        for i in range(self.cls_num):\n",
    "            cls_num_list.append(self.num_per_cls_dict[i])\n",
    "        return cls_num_list\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "class IMBALANCECIFAR100(IMBALANCECIFAR10):\n",
    "    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "    This is a subclass of the `CIFAR10` Dataset.\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-100-python'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\"\n",
    "    filename = \"cifar-100-python.tar.gz\"\n",
    "    tgz_md5 = 'eb9058c3a382ffc7106e4002c42a8d85'\n",
    "    train_list = [\n",
    "        ['train', '16019d7e3df5f24257cddd939b257f8d'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test', 'f0ef6b0ae62326f3e7ffdfab6717acfc'],\n",
    "    ]\n",
    "    meta = {\n",
    "        'filename': 'meta',\n",
    "        'key': 'fine_label_names',\n",
    "        'md5': '7973b15100ade9c7d40fb424638fde48',\n",
    "    }\n",
    "    cls_num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EtxYeHjRVO9S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for testing\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        # TODO 1, data transform for train set. Use RandomHorizontalFlip function for data augumentation\n",
    "        ################################ TODO ##################################\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        ################################ TODO ##################################\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Load CIFAR10\n",
    "image_datasets = {x: IMBALANCECIFAR10(root='./data', train=(x=='train'), download=True, transform=data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=(x=='train'), num_workers=16) for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "#print(dataset_sizes)\n",
    "# Move to GPU\n",
    "device = torch.device(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x15145042ae10>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x151450a1fd50>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, (3,3), stride=(1,1),padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 64, (3,3), stride=(1,1), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, ceil_mode=False),            \n",
    "            \n",
    "            nn.Conv2d(64, 128, (3,3), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            \n",
    "            nn.Conv2d(128, 128, (3,3),padding=1),\n",
    "            nn.BatchNorm2d(128),            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2, stride=2),            \n",
    "            \n",
    "            nn.Conv2d(128, 256, (3,3),padding=1),\n",
    "            nn.BatchNorm2d(256),            \n",
    "            nn.ReLU(),         \n",
    "            \n",
    "            nn.Conv2d(256, 256, (3,3),padding=1),\n",
    "            nn.BatchNorm2d(256),            \n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, (3,3),padding=1),\n",
    "            nn.BatchNorm2d(512),            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(512, 512, (3,3),padding=1),\n",
    "            nn.BatchNorm2d(512),            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(512, 512, (3,3),padding=1),\n",
    "            nn.BatchNorm2d(512),            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(512, 512, (3,3),padding=1),\n",
    "            nn.BatchNorm2d(512),            \n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(512,128),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(128,10)\n",
    "        )    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, 512)\n",
    "\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "model_mynet_ft = MyNet()\n",
    "model_mynet_ft = model_mynet_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_Y2cgPEVO9X"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs, dataloader, size=None, save_path='saved_weight.pth'):\n",
    "    since = time.time()\n",
    "    loss_record = [] # Frost: for plot\n",
    "    dataset_sizes_train = size\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train': model.train()  # Set model to training mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloader[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                #import pdb; pdb.set_trace()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes_train\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes_train\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            loss_record.append(epoch_loss)\n",
    "            \n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        model_test = model\n",
    "        test_model(model_test, save_path)\n",
    "    print()\n",
    "\n",
    "    plt.plot(loss_record)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    model_test = model\n",
    "    test_model(model, save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtE6iv9rVO9w"
   },
   "outputs": [],
   "source": [
    "def test_model(model, load_path='saved_weight.pth'):    \n",
    "    # load the model weights\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    for phase in ['test']:\n",
    "        if phase == 'test':\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                ################################ TODO ##################################\n",
    "                outputs = model(inputs)\n",
    "                preds = torch.max(outputs, 1)[1]\n",
    "                ################################ TODO ##################################\n",
    "\n",
    "            # statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print('{} Acc: {:.4f}'.format(phase, epoch_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return epoch_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_most_inform():\n",
    "    def __init__(self, image_tensor, labels, transform=data_transforms, target_transform=None):\n",
    "        self.img_labels = labels #list\n",
    "        self.img_tensors = image_tensor #also list\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.img_tensors[idx]\n",
    "        label = self.img_labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "    \n",
    "def sampling(model, dataset, load_path='saved_weight.pth', ):\n",
    "    model.load_state_dict(torch.load(load_path)) \n",
    "    cifar10 = dataset\n",
    "    class_list = cifar10.get_cls_num_list()\n",
    "    class_freq = {}\n",
    "  \n",
    "    for i, x in zip(cifar10.class_to_idx, class_list):\n",
    "        class_freq[cifar10.class_to_idx[i]] = x\n",
    "\n",
    "    smallest = class_freq[5]\n",
    "\n",
    "\n",
    "    model.eval()   \n",
    "    accuracy_9 = 0\n",
    "    num_samples = smallest\n",
    "    class_to_samples = {}\n",
    "    for k in range(10):\n",
    "        \n",
    "        for inputs, labels in dataloaders['train']:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs) \n",
    "                preds = torch.max(outputs, 1)[1]\n",
    "                softmax = nn.Softmax(dim=1)\n",
    "                prob = softmax(outputs)\n",
    "                #image by image\n",
    "                for i, y, z, x in zip(prob, inputs, labels, preds):\n",
    "                    if z.item() == k:\n",
    "                        if k not in class_to_samples:\n",
    "                            class_to_samples[k]= [[y, z, i[k]]]\n",
    "                        else:\n",
    "                            class_to_samples[k] += [[y, z, i[k]]]\n",
    "    \n",
    "  \n",
    "    no_sampling = [5, 6, 7, 8, 9]\n",
    "    dataset_dct = {}\n",
    " \n",
    "    for i in class_to_samples:\n",
    "        class_to_samples[i] = sorted(class_to_samples[i], key=itemgetter(2))\n",
    "  \n",
    "    for i in class_to_samples:\n",
    "        if i in no_sampling:\n",
    "            dataset_dct[i] = []\n",
    "            for s in class_to_samples[i]: \n",
    "                dataset_dct[i] += [s]\n",
    "                \n",
    "        dataset_dct[i] = []\n",
    "        count = 0\n",
    "        for s in class_to_samples[i]:\n",
    "            if count == smallest:\n",
    "                break\n",
    "            count += 1\n",
    "            dataset_dct[i] += [s]\n",
    "    \n",
    "#     for i in dataset_dct:\n",
    "#         for s in dataset_dct[i]:\n",
    "#             print(len(dataset_dct[i]), s)\n",
    "   \n",
    "    lst_images = []\n",
    "    lst_labels = []\n",
    "    for i in dataset_dct:\n",
    "        for s in dataset_dct[i]:\n",
    "            lst_images.append(s[0])\n",
    "            lst_labels.append(s[1])\n",
    "   \n",
    "    dataset_sampled = dataset_most_inform(lst_images, lst_labels)\n",
    "    New_dataloader = {'train': torch.utils.data.DataLoader(dataset_sampled, batch_size=32, shuffle=True)}#, num_workers=16)}\n",
    "\n",
    "    return New_dataloader, len(dataset_sampled)\n",
    "\n",
    "\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def ITLM(model, criterion, optimizer, do_meta=False, eps=0.1,total_epochs=50, pretrained_epochs=25,inner_epochs=10, save_path='saved_weight.pth'):\n",
    "\n",
    "\n",
    "    # pretrain the model\n",
    "    train_model(model, criterion, optimizer, pretrained_epochs, dataloaders,dataset_sizes['train'], save_path='saved_weight.pth')\n",
    "    \n",
    "    \n",
    "    # load the data and sample the data\n",
    "    cifar10 = IMBALANCECIFAR10(root='./data')\n",
    "    meta_epochs = total_epochs - pretrained_epochs\n",
    "    iter_1_loader, sampled_size = sampling(model, cifar10)\n",
    "    original_datasize = dataset_sizes['train']\n",
    "    \n",
    "    # do the meta epochs  \n",
    "    for meta_epoch in range(int(original_datasize*meta_epochs/(sampled_size*inner_epochs))):\n",
    "        prev_model_params = deepcopy(model.state_dict())\n",
    "        train_model(model, criterion, optimizer, inner_epochs, iter_1_loader, sampled_size, save_path='saved_weight.pth')\n",
    "        current_model_params = deepcopy(model.state_dict())\n",
    "        #import pdb; pdb.set_trace()\n",
    "        \n",
    "        for param_name in current_model_params.keys():\n",
    "            current_model_params[param_name] = (1-eps)*prev_model_params[param_name] + eps*current_model_params[param_name]\n",
    "        if do_meta:\n",
    "            model.load_state_dict(current_model_params)\n",
    "        \n",
    "        iter_1_loader, sampled_size = sampling(model, cifar10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpRAJHrtVO9o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(model_mynet_ft, (3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please do the following experiments:\n",
    "1. train the model on Balanced dataset, record the performance\n",
    "2. train the model on imbalanced dataset, record the performance\n",
    "3. train the model on imbalanced dataset, with iterative learning strategy\n",
    "4. train the model on imbalanced dataset, with meta iterative learning strategy # do_mate=True\n",
    "\n",
    "set the eps from 0.1 to 0.9. step size = 0.1, Record the best.\n",
    "\n",
    "set the inner epochs from 5 to 20, step size=5.\n",
    "\n",
    "use the accuracy, precision, recall, f1 score to measure the final performance. The detailed information is here.https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "\n",
    "## Each experiments run 5 times. Record the mean and variance of each metrics.\n",
    "\n",
    "### The most important thing: Reset the model parameters before excuting the steps.\n",
    "\n",
    "Fixed hyperparameters: the transformation step is fixed.\n",
    "    Total epoch = 50, pretrained_epochs=20, lr=1e-4\n",
    "Flexible hyperparameters: \n",
    "    eps, inner_epochs, \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.1378 Acc: 0.9531\n",
      "test Acc: 0.8051\n",
      "Testing complete in 0m 1s\n",
      "\n",
      "Training complete in 0m 7s\n",
      "test Acc: 0.8051\n",
      "Testing complete in 0m 1s\n",
      "Files already downloaded and verified\n",
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.3382 Acc: 0.8882\n",
      "test Acc: 0.8023\n",
      "Testing complete in 0m 1s\n",
      "\n",
      "Training complete in 0m 2s\n",
      "test Acc: 0.8023\n",
      "Testing complete in 0m 1s\n",
      "> <ipython-input-36-288a1cbe2502>(25)ITLM()\n",
      "-> if do_meta:\n",
      "(Pdb) exit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d0655c96e9f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mynet_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model_mynet_ft = train_model(model_mynet_ft, criterion, optimizer, num_epochs=1, save_path='saved_own_loop.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mITLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mynet_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdo_meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpretrained_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minner_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saved_weight.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mynet_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'saved_weight.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-288a1cbe2502>\u001b[0m in \u001b[0;36mITLM\u001b[0;34m(model, criterion, optimizer, do_meta, eps, total_epochs, pretrained_epochs, inner_epochs, save_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcurrent_model_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprev_model_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcurrent_model_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdo_meta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_model_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-288a1cbe2502>\u001b[0m in \u001b[0;36mITLM\u001b[0;34m(model, criterion, optimizer, do_meta, eps, total_epochs, pretrained_epochs, inner_epochs, save_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcurrent_model_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprev_model_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcurrent_model_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdo_meta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_model_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tape/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tape/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_mynet_ft.parameters(), lr=1e-4)\n",
    "#model_mynet_ft = train_model(model_mynet_ft, criterion, optimizer, num_epochs=1, save_path='saved_own_loop.pth')\n",
    "ITLM(model_mynet_ft, criterion, optimizer,do_meta=True, eps=0.9,pretrained_epochs=1,inner_epochs=1, save_path='saved_weight.pth')\n",
    "test_model(model_mynet_ft, load_path='saved_weight.pth')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc: 0.8160\n",
      "Testing complete in 0m 7s\n"
     ]
    }
   ],
   "source": [
    "acc = test_model(model_mynet_ft, load_path='saved_weight.pth')\n",
    "\n",
    "#assert acc>0.8, 'Please fune-tune your model to reach a higher accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_Image_Classification.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
